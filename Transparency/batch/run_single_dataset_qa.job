#!/bin/bash

#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=FirstRun
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=02:00:00
#SBATCH --mem=32000M
#SBATCH --mail-type=END
#SBATCH --mail-user=blazej.dol@gmail.com

module purge
module load 2019
module load Python/3.7.5-foss-2019b
module load CUDA/10.1.243
module load cuDNN/7.6.5.32-CUDA-10.1.243
module load NCCL/2.5.6-CUDA-10.1.243
module load Anaconda3/2018.12

# Go to the script dir
cd $HOME/Transparency/Transparency

# Activate your environment
source activate fact_paper

# Line required by the repo
export PYTHONPATH=$HOME/Transparency

# Run the script and train the model
dataset_name=snli
model_name=diversity_lstm
output_path=./experiments
diversity_weight=0.5
attention=tanh
# n_epochs=5
python train_and_run_experiments_qa.py --dataset ${dataset_name} --data_dir . --output_dir ${output_path} --encoder ${model_name} --diversity ${diversity_weight} --attention ${attention}

